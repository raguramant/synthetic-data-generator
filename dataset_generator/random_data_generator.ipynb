{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be30ec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q faker\n",
    "%pip install -q jsonschema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07b550",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d64b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonschema\n",
    "from faker import Faker\n",
    "import string\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10c89f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_training_records_per_schema = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aea149",
   "metadata": {},
   "source": [
    "### Load Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcea36ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dtp_schema.json', 'isa_schema.json', 'name_schema.json', 'ref_schema.json'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "schema_files = [f for f in os.listdir('schema') if f.endswith('.json')]\n",
    "\n",
    "schemas = {}\n",
    "for schema_file in schema_files:\n",
    "    with open(os.path.join('schema', schema_file), 'r') as f:\n",
    "        schemas[schema_file] = json.load(f)\n",
    "\n",
    "print(schemas.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5bf1f",
   "metadata": {},
   "source": [
    "### Random Data Generator for Json Schema Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdb654e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonPropertyValueGenerator:\n",
    "\n",
    "    def __init__(self, faker=None):\n",
    "        if faker:\n",
    "            self._faker = faker\n",
    "        else:\n",
    "            self._faker = Faker()\n",
    "        self.null_threshold = 0.4\n",
    "\n",
    "    def get_property_value_generators(self, schema: dict, include_nulls=True) -> dict:\n",
    "\n",
    "        properties = schema.get('properties', {})\n",
    "        required_properties = schema.get('required', [])\n",
    "        value_generators = {}\n",
    "\n",
    "        for prop_name, prop_schema in properties.items():\n",
    "\n",
    "            nulls = include_nulls and (prop_name not in required_properties)\n",
    "\n",
    "            if prop_schema.get('type') == 'string':\n",
    "                value_generators[prop_name] = self.get_string_generator(prop_name, prop_schema, nulls)\n",
    "            elif prop_schema.get('type') == 'integer':\n",
    "                value_generators[prop_name] = lambda: None if nulls and random.random() < self.null_threshold \\\n",
    "                    else self._faker.random_int(min=0, max=1000)\n",
    "            elif prop_schema.get('type') == 'boolean':\n",
    "                value_generators[prop_name] = lambda: None if nulls and random.random() < self.null_threshold \\\n",
    "                    else self._faker.boolean()\n",
    "            elif prop_schema.get('type') == 'null' and nulls:\n",
    "                value_generators[prop_name] = lambda: None\n",
    "            else:\n",
    "                value_generators[prop_name] = lambda: None\n",
    "\n",
    "        return value_generators\n",
    "\n",
    "    def get_string_generator(self, property_name=None, prop_schema=None, include_nulls=True):\n",
    "        if \"enum\" in prop_schema:\n",
    "            return lambda: None if include_nulls and random.random() < self.null_threshold \\\n",
    "                else self._faker.random_element(elements=prop_schema[\"enum\"])\n",
    "        elif prop_schema.get(\"format\") == \"email\":\n",
    "            return lambda: None if include_nulls and random.random() < self.null_threshold else self._faker.email()\n",
    "\n",
    "        elif prop_schema.get(\"format\") == \"date\":\n",
    "            return lambda: None if include_nulls and random.random() < self.null_threshold else self._faker.date(pattern=\"%y%m%d\")\n",
    "        \n",
    "        elif prop_schema.get(\"format\") == \"time\":\n",
    "            return lambda: None if include_nulls and random.random() < self.null_threshold else self._faker.time(pattern=\"%H%M\")\n",
    "\n",
    "        elif \"minLength\" in prop_schema or \"maxLength\" in prop_schema:\n",
    "            description = prop_schema.get(\"description\", \"\")\n",
    "\n",
    "            if (\"name\" in description.lower() and \"first\" in description.lower()) or \\\n",
    "               (\"name\" in property_name.lower() and \"first\" in property_name.lower()):\n",
    "                return lambda: None if include_nulls and random.random() < self.null_threshold \\\n",
    "                    else self._faker.first_name()\n",
    "\n",
    "            elif (\"name\" in description.lower() and \"last\" in description.lower()) or \\\n",
    "                 (\"name\" in property_name.lower() and \"last\" in property_name.lower()):\n",
    "                return lambda: None if include_nulls and random.random() < self.null_threshold \\\n",
    "                    else self._faker.last_name()\n",
    "\n",
    "            elif (\"name\" in description.lower() and \"middle\" in description.lower()) or \\\n",
    "                 (\"name\" in property_name.lower() and \"middle\" in property_name.lower()):\n",
    "                return lambda: None if include_nulls and random.random() < self.null_threshold \\\n",
    "                    else self._faker.random_element(elements=list(string.ascii_uppercase))\n",
    "\n",
    "            elif (\"name\" in description.lower() and \"prefix\" in description.lower()) or \\\n",
    "                 (\"name\" in property_name.lower() and \"prefix\" in property_name.lower()):\n",
    "                return lambda: None if include_nulls and random.random() < self.null_threshold else self._faker.prefix()\n",
    "\n",
    "            elif (\"name\" in description.lower() and \"suffix\" in description.lower()) or \\\n",
    "                 (\"name\" in property_name.lower() and \"suffix\" in property_name.lower()):\n",
    "                return lambda: None if include_nulls and random.random() < self.null_threshold else self._faker.suffix()\n",
    "\n",
    "            elif \"name\" in description.lower() or \"name\" in property_name.lower():\n",
    "                return lambda: None if include_nulls and random.random() < self.null_threshold else self._faker.name()\n",
    "\n",
    "            else:\n",
    "                return lambda: None if include_nulls and random.random() < self.null_threshold \\\n",
    "                    else self._faker.pystr(min_chars=prop_schema.get(\"minLength\", 1), max_chars=prop_schema.get(\"maxLength\", 10))\n",
    "        else:\n",
    "            return lambda: self._faker.pystr(min_chars=1,max_chars=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8eee8d",
   "metadata": {},
   "source": [
    "### Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bebfefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json(json_data, target_schema=None) -> bool:\n",
    "    try:\n",
    "        jsonschema.validate(instance=json_data, schema=target_schema)\n",
    "        return True\n",
    "    except jsonschema.ValidationError as e:\n",
    "        print(f\"Validation error for object: {e}\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "def remove_none(d):\n",
    "    if isinstance(d, dict):\n",
    "        return {k: remove_none(v) for k, v in d.items() if v is not None}\n",
    "    elif isinstance(d, list):\n",
    "        return [remove_none(v) for v in d if v is not None]\n",
    "    else:\n",
    "        return d\n",
    "    \n",
    "def get_nm1_segment(rec):\n",
    "    entity_identifier_code = rec.get(\"entity_identifier_code\", \"\")\n",
    "    entity_type_qualifier = rec.get(\"entity_type_qualifier\", \"\")\n",
    "    name_last_or_organization_name = rec.get(\"name_last_or_organizationName\", \"\")\n",
    "    name_first = rec.get(\"name_first\", \"\")\n",
    "    name_middle = rec.get(\"name_middle\", \"\")\n",
    "    name_prefix = rec.get(\"name_prefix\", \"\")\n",
    "    name_suffix = rec.get(\"name_suffix\", \"\")\n",
    "    identification_code_qualifier = rec.get(\"identification_code_qualifier\", \"\")\n",
    "    identification_code = rec.get(\"identification_code\", \"\")\n",
    "    return f\"NM1*{entity_identifier_code}*{entity_type_qualifier}*{name_last_or_organization_name}*{name_first}*{name_middle}*{name_prefix}*{name_suffix}*{identification_code_qualifier}*{identification_code}~\"\n",
    "\n",
    "\n",
    "def get_ref_segment(rec):\n",
    "    reference_identification_qualifier = rec.get(\"reference_identification_qualifier\", \"\")\n",
    "    reference_identification = rec.get(\"reference_identification\", \"\")\n",
    "    ref_segment = rec.get(\"ref_segment\", \"\")\n",
    "    nm1_segment = get_nm1_segment(rec)\n",
    "    return f\"REF*{reference_identification_qualifier}*{reference_identification}~\"\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def dtp_segment(rec):\n",
    "    date_qualifier = random.choice([\"291\", \"348\", \"349\", \"050\", \"151\", \"152\", \"153\", \"154\", \"155\", \"156\"])\n",
    "    date_type = random.choice([\"D8\",\"RD8\"])\n",
    "    dt = Faker().date_object()\n",
    "    formatted_date_from = dt.strftime(\"%Y%m%d\")\n",
    "    # date_obj = datetime.strptime(formatted_date_from, \"%Y%m%d\")\n",
    "    new_date_obj = dt + timedelta(days=5)  # Add 5 days\n",
    "    formatted_date_to = new_date_obj.strftime(\"%Y%m%d\")\n",
    "\n",
    "    if type == \"D8\":\n",
    "        dtp = f\"DTP*{date_qualifier}*{date_type}*{formatted_date_from}\"\n",
    "    else:\n",
    "        dtp = f\"DTP*{date_qualifier}*{date_type}*{formatted_date_from}-{formatted_date_to}\"\n",
    "    return dtp\n",
    "\n",
    "\n",
    "def isa_segment(rec):\n",
    "    isa01 = rec.get(\"authorization_information_qualifier\", \"\")\n",
    "    isa02 = rec.get(\"authorization_information\", \"\")\n",
    "    isa03 = rec.get(\"security_information_qualifier\", \"\")\n",
    "    isa04 = rec.get(\"security_information\", \"\")\n",
    "    isa05 = rec.get(\"interchange_sender_id_qualifier\", \"\")\n",
    "    isa06 = rec.get(\"interchange_sender_id\", \"\")\n",
    "    isa07 = rec.get(\"interchange_receiver_id_qualifier\", \"\")\n",
    "    isa08 = rec.get(\"interchange_receiver_id\", \"\")\n",
    "    isa09 = rec.get(\"interchange_date\", \"\")\n",
    "    isa10 = rec.get(\"interchange_time\", \"\")\n",
    "    isa11 = rec.get(\"repetition_separator\", \"\")\n",
    "    isa12 = rec.get(\"interchange_control_version_number\", \"\")\n",
    "    isa13 = rec.get(\"interchange_control_number\", \"\")\n",
    "    isa14 = rec.get(\"acknowledgment\", \"\")\n",
    "    isa15 = rec.get(\"usage_indicator\", \"\")\n",
    "    isa16 = rec.get(\"element_separator\", \"\")\n",
    "    return f\"ISA*{isa01}*{isa02}*{isa03}*{isa04}*{isa05}*{isa06}*{isa07}*{isa08}*{isa09}*{isa10}*{isa11}*{isa12}*{isa13}*{isa14}*{isa15}*{isa16}~\"  \n",
    "\n",
    "\n",
    "custom_properties = {\n",
    "    \"nm1_segment\": get_nm1_segment,\n",
    "    \"ref_segment\": get_ref_segment,\n",
    "    \"dtp_segment\": dtp_segment,\n",
    "    \"isa_segment\": isa_segment\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297574e",
   "metadata": {},
   "source": [
    "### Prompt Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "909ced6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_prompt(json_data, schema) -> dict:\n",
    "\n",
    "    record = {\n",
    "        \"messages\":[]\n",
    "    }\n",
    "\n",
    "    record['messages'].append(get_user_content(json_data, schema)) #user\n",
    "    record['messages'].append(get_assistant_content(json_data)) #user\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def get_user_content(json_data, schema):\n",
    "    \n",
    "    context_example = [\n",
    "        \"You are a Json test data generator generating valid json data based on a json schema. \",\n",
    "        \"You are a sample data generator that creates valid JSON data based on a schema.\",\n",
    "        \"You are a structured data generator that creates valid JSON data based on a schema.\"\n",
    "    ]\n",
    "\n",
    "    context = random.choice(context_example)\n",
    "    prompt = get_user_prompt(json_data, schema)\n",
    "    schema = f\"\\nGiven the Schema: {json.dumps(schema)}\" if not schema.get('title') in prompt else \"\"\n",
    "    \n",
    "    content = f\"{context}{schema}\\n{prompt}\"\n",
    "    return  {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":f\"{content}\"\n",
    "    }\n",
    "\n",
    "\n",
    "def get_user_prompt(json_data, schema):\n",
    "\n",
    "    schema_name = schema.get('title', '')\n",
    "    # convert json_data keys to a comma-separated string\n",
    "    properties = \", \".join(json_data.keys())\n",
    "    # convert json_data values to a comma-separated string\n",
    "    values = \", \".join([str(value) for value in json_data.values() if value is not None])\n",
    "    # convert schema required properties to a comma-separated string\n",
    "    required_properties = \", \".join(schema.get('required', []))\n",
    "    # convert json_data properties and values to a formatted string\n",
    "    properties_and_values = \", \".join([f\"{key}: {value}\" for key, value in json_data.items() if value is not None])\n",
    "\n",
    "    templates = [\n",
    "        \"Create a JSON object that adheres to the given schema\",\n",
    "        \"Produce a JSON object that conforms to the specified schema\",\n",
    "        \"Generate a valid JSON object with the following properties: {properties}\",\n",
    "        \"Generate a JSON object that includes the following properties: {properties}\",\n",
    "        \"Create a JSON object with the required properties: {required_properties}\",\n",
    "        \"Give a JSON data that has the required properties: {required_properties}\",\n",
    "        \"Generate a JSON object with the following properties: {properties} and values: {values}\",\n",
    "        \"Create a JSON object that contains the following properties: {properties} and values: {values}\",        \n",
    "        \"Generate a JSON object that includes the following properties and values: {properties_and_values}\",\n",
    "        \"Create a JSON object that contains the following properties and values: {properties_and_values}\",\n",
    "        \"Generate a sample json for the {schema_name} schema\",\n",
    "        \"Get a sample json for the {schema_name} schema\",\n",
    "        \"Give a sample for the {schema_name} schema\",\n",
    "    ]\n",
    "    only_required_properties_templates = [\n",
    "        \"Generate a JSON object that includes only the required properties\",\n",
    "        \"Create a JSON object that contains only the required properties\",\n",
    "        \"Produce a JSON object that adheres to the schema with only the required properties: {required_properties}\",\n",
    "        \"Generate a JSON object that includes the required properties\",\n",
    "        \"Create a JSON object that contains the required properties: {required_properties}\",\n",
    "        \"Produce a JSON object that adheres to the schema with only the required properties\",\n",
    "        \"Generate a JSON object that includes the required properties: {required_properties}\",\n",
    "        \"Create a sample JSON object that contains the required properties: {required_properties}\",\n",
    "        \"Generate a sample json for the {schema_name} schema with only required properties\",\n",
    "        \"Get a sample json for the {schema_name} schema and include only required properties\"\n",
    "        \n",
    "    ]\n",
    "    all_properties_templates = [\n",
    "        \"Generate a JSON object that includes all properties\",\n",
    "        \"Create a JSON object that contains all properties\",\n",
    "        \"Produce a JSON object that adheres to the schema with all properties\",\n",
    "        \"Generate a JSON object that includes all properties\",\n",
    "        \"Create a JSON object that contains all properties\",\n",
    "        \"Produce a JSON object that adheres to the schema with all properties\",\n",
    "        \"Generate a sample json for the {schema_name} schema with all properties\",\n",
    "        \"Give a sample for the {schema_name} schema and include all properties\"\n",
    "    ]\n",
    "    \n",
    "    # does json_data contain all properties in the schema?\n",
    "    has_all_properties = set(json_data.keys()) == set(schema.get('properties', {}).keys())\n",
    "    has_only_required_properties = set(json_data.keys()) == set(schema.get('required', []))\n",
    "\n",
    "    if has_all_properties:\n",
    "        template = random.choice(all_properties_templates)\n",
    "    elif has_only_required_properties:\n",
    "        template = random.choice(only_required_properties_templates)\n",
    "    else:\n",
    "        template = random.choice(templates)\n",
    "\n",
    "    prompt = template.format(\n",
    "        properties=properties,\n",
    "        values=values,\n",
    "        schema_name=schema_name,\n",
    "        required_properties=required_properties,\n",
    "        properties_and_values=properties_and_values\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_assistant_content(json_data):\n",
    "    \n",
    "    return  {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"{json.dumps(json_data)}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f7cd1",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467d0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 250 records for schema: dtp_schema.json\n",
      "Generating 250 records for schema: isa_schema.json\n",
      "Generating 250 records for schema: name_schema.json\n",
      "Generating 250 records for schema: ref_schema.json\n"
     ]
    }
   ],
   "source": [
    "value_generator_utils = JsonPropertyValueGenerator()\n",
    "\n",
    "generators = {}\n",
    "for schema_name, schema in schemas.items():\n",
    "    generators[schema_name] = value_generator_utils.get_property_value_generators(schema, include_nulls=True)\n",
    "\n",
    "records = []\n",
    "for schema_name, generator in generators.items():\n",
    "    print(f\"Generating {no_of_training_records_per_schema} records for schema: {schema_name}\")\n",
    "    records_generated = 0\n",
    "    while records_generated < no_of_training_records_per_schema:\n",
    "        record = {}\n",
    "        for key, generate in generator.items():\n",
    "            record[key] = generate() \n",
    "\n",
    "        record = remove_none(record)\n",
    "\n",
    "        for custom_property, custom_function in custom_properties.items():\n",
    "            if custom_property in schemas.get(schema_name).get('properties', {}):\n",
    "                record[custom_property] = custom_function(record)\n",
    "        \n",
    "        # record['nm1_segment'] = get_nm1_segment(record)\n",
    "\n",
    "        if validate_json(record, schemas.get(schema_name)):\n",
    "            record = generate_prompt(record, schemas.get(schema_name))\n",
    "            records.append(record)\n",
    "            records_generated += 1\n",
    "\n",
    "\n",
    "#shuffle the records\n",
    "random.shuffle(records)\n",
    "\n",
    "with open(\"../data/combinations.jsonl\", \"w\") as outfile:\n",
    "    for record in records:\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
