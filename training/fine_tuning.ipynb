{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08fc88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (0.46.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (1.10.0)\n",
      "Requirement already satisfied: torch<3,>=2.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from bitsandbytes) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from bitsandbytes) (2.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch<3,>=2.2->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch<3,>=2.2->bitsandbytes) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch<3,>=2.2->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (4.55.0)\n",
      "Collecting peft\n",
      "  Using cached peft-0.17.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from peft) (2.8.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from peft) (1.10.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.13.0->peft) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Using cached peft-0.17.0-py3-none-any.whl (503 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mlflow in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (3.2.0)\n",
      "Requirement already satisfied: mlflow-skinny==3.2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (3.2.0)\n",
      "Requirement already satisfied: mlflow-tracing==3.2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (3.2.0)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (1.16.4)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (3.10.5)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (2.3.2)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (2.3.1)\n",
      "Requirement already satisfied: pyarrow<22,>=4.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (21.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (1.7.1)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (1.16.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (2.0.42)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (0.62.0)\n",
      "Requirement already satisfied: fastapi<1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (0.116.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (1.36.0)\n",
      "Requirement already satisfied: packaging<26 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (2.11.7)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (2.32.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (4.14.1)\n",
      "Requirement already satisfied: uvicorn<1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.2.0->mlflow) (0.35.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from click<9,>=7.0->mlflow-skinny==3.2.0->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (2.40.3)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from docker<8,>=4.0.0->mlflow) (311)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from fastapi<1->mlflow-skinny==3.2.0->mlflow) (0.47.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.2.0->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.2.0->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.2.0->mlflow) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<4->mlflow) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<4->mlflow) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.2.0->mlflow) (0.57b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.2.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.2.0->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.2.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.2.0->mlflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.2.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.2.0->mlflow) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.2.0->mlflow) (4.10.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.2.0->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from uvicorn<1->mlflow-skinny==3.2.0->mlflow) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install  transformers peft\n",
    "# %pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n",
    "# %pip install  bitsandbytes accelerate\n",
    "# %pip install ipywidgets\n",
    "# %pip install sentencepiece #conda install sentencepiece\n",
    "# %pip install  mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855e895",
   "metadata": {},
   "source": [
    "### Login to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc7b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "\n",
    "# notebook_login()\n",
    "# Set the Hugging Face token as an environment variable\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "# os.environ[\"HF_HOME\"] = \"C:\\\\Users\\\\Admin\\\\.cache\\\\huggingface\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ebd775",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "\n",
    "#Model configs\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "f_checkpoint_dir = \"../output/{experiment_name}/checkpoints\"\n",
    "f_model_output_dir = \"../output/{experiment_name}/adapters/{epoch}\"\n",
    "training_data = \"../data/property_style_training_data_v1.jsonl\"\n",
    "\n",
    "num_train_epochs = 6\n",
    "mlflow_experiment_name = \"Approach_1_Multiple_Schemas\"\n",
    "# mlflow_experiment_name = \"Approach_2_Property_Style\"\n",
    "mlflow_run_name = \"run-1\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddca8082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc30042fc53e469bb35bcb4c7dec1911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config ,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf4511",
   "metadata": {},
   "source": [
    "### Configure PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e630054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,631,488 || all params: 7,261,655,040 || trainable%: 0.1877\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7fa15c",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4b21ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30971657d78342069526bc197a652fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a28ad29b7745648f99deefe7f65640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007b4b4942de455d9f87267272845e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/112 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 784\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 224\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 112\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "# load the dataset and split it into train, validation and test sets\n",
    "dataset = load_dataset(\"json\", data_files=training_data, split='train')\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "train_temp_split = shuffled_dataset.train_test_split(test_size=0.3) #30% for validation and test\n",
    "temp_dataset = train_temp_split['test']\n",
    "validation_test_split = temp_dataset.train_test_split(test_size=1/3)# 10% for validation and 20% for test\n",
    "split_datasets = DatasetDict({\n",
    "    'train': train_temp_split['train'],\n",
    "    'validation': validation_test_split['train'],\n",
    "    'test': validation_test_split['test']\n",
    "})\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "MAX_LENGTH = 3000\n",
    "\n",
    "\n",
    "def tokenize_with_loss_mask(example):\n",
    "    chat_str = tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)\n",
    "    tokenized = tokenizer(chat_str, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "\n",
    "    input_ids = tokenized[\"input_ids\"]\n",
    "    labels = []\n",
    "\n",
    "    seq_start_idx = 0 # start of sequence\n",
    "    total_length = len(chat_str)\n",
    "\n",
    "    while seq_start_idx < total_length:\n",
    "\n",
    "        # print(\"-----------------------\")\n",
    "        seq_end_idx = chat_str.find(\"</s>\", seq_start_idx)+ len(\"</s>\") # end of sequence\n",
    "        if seq_end_idx == -1:\n",
    "            break\n",
    "\n",
    "        sequence = chat_str[seq_start_idx:seq_end_idx]\n",
    "        end_user_idx = sequence.find(\"[/INST]\")+ len(\"[/INST]\") # end of user message\n",
    "        end_assistant_idx = sequence.find(\"</s>\")\n",
    "        user_content = sequence[:end_user_idx]\n",
    "        assistant_content = sequence[end_user_idx:end_assistant_idx]\n",
    "\n",
    "        seq_tokens = tokenizer(sequence, add_special_tokens=False)[\"input_ids\"]\n",
    "        user_tokens = tokenizer(user_content, add_special_tokens=False)[\"input_ids\"]\n",
    "        assistant_tokens = tokenizer(assistant_content, add_special_tokens=False)[\"input_ids\"]\n",
    "        \n",
    "        labels.extend([-100] * len(user_tokens))\n",
    "        labels.extend(assistant_tokens)\n",
    "        labels.extend([-100] * (len(seq_tokens) - len(user_tokens) - len(assistant_tokens)))\n",
    "        \n",
    "        seq_start_idx = seq_end_idx\n",
    "\n",
    "    labels = [-100] * (len(input_ids) - len(labels)) + labels  # Pad to max length\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    if len(tokenized[\"input_ids\"]) > MAX_LENGTH:\n",
    "        print(\"Warning: Input sequence exceeds max length for inputs, truncating.\")\n",
    "    if len(tokenized[\"labels\"]) > MAX_LENGTH:\n",
    "        print(\"Warning: Input sequence exceeds max length for labels, truncating.\")\n",
    "    if len(tokenized[\"input_ids\"]) != len(tokenized[\"labels\"]):\n",
    "        print(\"Error: Input and label lengths do not match after processing.\")\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = split_datasets.map(tokenize_with_loss_mask, remove_columns=split_datasets[\"train\"].column_names)\n",
    "print(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7b7ea",
   "metadata": {},
   "source": [
    "### Setup MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644bc49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: file:c:\\Users\\Admin\\Documents\\Projects\\Repositories\\synthetic-data-generator/mlruns\n",
      "Starting MLflow run with ID: 3fb5ee5e6f584fda9aecfeebf320b5fe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/property_style_training_data_v1.jsonl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "def get_last_run_id_for_run_name(experiment_name, run_name):\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(experiment_name)\n",
    "    runs = client.search_runs(experiment.experiment_id, filter_string=f\"tags.mlflow.runName='{run_name}'\", order_by=[\"attributes.start_time DESC\"], max_results=1)\n",
    "\n",
    "    if runs:\n",
    "        return runs[0].info.run_id\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "mlflow_tracking_uri = f\"file:{os.path.dirname(os.getcwd())}/mlruns\"  \n",
    "print(\"MLflow tracking URI:\", mlflow_tracking_uri)\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_experiment(mlflow_experiment_name)\n",
    "mlflow_run_id = get_last_run_id_for_run_name(mlflow_experiment_name, mlflow_run_name)\n",
    "checkpoint_dir = f_checkpoint_dir.format(experiment_name=mlflow_experiment_name)\n",
    "model_output_dir = f_model_output_dir.format(experiment_name=mlflow_experiment_name, epoch=f\"epoch-{num_train_epochs}\")\n",
    "\n",
    "if mlflow_run_id:\n",
    "    print(\"Starting MLflow run with ID:\", mlflow_run_id)\n",
    "    mlflow.start_run(run_id=mlflow_run_id)\n",
    "else:\n",
    "    print(\"Starting new MLflow run with name:\", mlflow_run_name)\n",
    "    mlflow.start_run(run_name=mlflow_run_name)\n",
    "\n",
    "mlflow.log_param(\"dataset\", training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8eecef",
   "metadata": {},
   "source": [
    "### Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "266488a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n",
      "You are adding a <class 'transformers.integrations.integration_utils.MLflowCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "MLflowCallback\n",
      "NotebookProgressCallback\n",
      "Loading model from ../output/Approach_2_Property_Style/checkpoints\\checkpoint-588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from latest checkpoint: ../output/Approach_2_Property_Style/checkpoints\\checkpoint-588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 784\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 588\n",
      "  Number of trainable parameters = 13,631,488\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 6\n",
      "  Continuing training from global step 588\n",
      "  Will skip the first 6 epochs then the first 0 batches in the first epoch.\n",
      "2025/08/10 23:31:29 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 3fb5ee5e6f584fda9aecfeebf320b5fe: Failed to log run data: Exception: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='../output/Approach_2_Property_Style/checkpoints\\runs\\Aug09_16-31-58_Ragus-pc' for run ID='3fb5ee5e6f584fda9aecfeebf320b5fe'. Attempted logging new value '../output/Approach_2_Property_Style/checkpoints\\runs\\Aug10_23-31-28_Ragus-pc'.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../output/Approach_2_Property_Style/checkpoints\\checkpoint-196 (score: 0.24124164879322052).\n",
      "2025/08/10 23:31:29 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 3fb5ee5e6f584fda9aecfeebf320b5fe: Failed to log run data: Exception: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='../output/Approach_2_Property_Style/checkpoints\\runs\\Aug09_16-31-58_Ragus-pc' for run ID='3fb5ee5e6f584fda9aecfeebf320b5fe'. Attempted logging new value '../output/Approach_2_Property_Style/checkpoints\\runs\\Aug10_23-31-28_Ragus-pc'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [588/588 : < :, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'epoch': 0.10204081632653061, 'grad_norm': 2.5200231075286865, 'learning_rate': 0.00019761904761904763, 'loss': 0.8889, 'step': 10}, {'epoch': 0.20408163265306123, 'grad_norm': 1.1737672090530396, 'learning_rate': 0.00019421768707482995, 'loss': 0.2648, 'step': 20}, {'epoch': 0.30612244897959184, 'grad_norm': 0.6160853505134583, 'learning_rate': 0.00019081632653061227, 'loss': 0.3972, 'step': 30}, {'epoch': 0.40816326530612246, 'grad_norm': 1.953173041343689, 'learning_rate': 0.00018741496598639456, 'loss': 0.3544, 'step': 40}, {'epoch': 0.5102040816326531, 'grad_norm': 1.4129852056503296, 'learning_rate': 0.00018401360544217688, 'loss': 0.3867, 'step': 50}, {'epoch': 0.6122448979591837, 'grad_norm': 1.1192444562911987, 'learning_rate': 0.00018061224489795917, 'loss': 0.375, 'step': 60}, {'epoch': 0.7142857142857143, 'grad_norm': 0.4610578417778015, 'learning_rate': 0.00017721088435374152, 'loss': 0.2869, 'step': 70}, {'epoch': 0.8163265306122449, 'grad_norm': 0.4413067698478699, 'learning_rate': 0.00017380952380952383, 'loss': 0.1679, 'step': 80}, {'epoch': 0.9183673469387755, 'grad_norm': 0.4764588177204132, 'learning_rate': 0.00017040816326530613, 'loss': 0.3228, 'step': 90}, {'epoch': 1.0, 'eval_loss': 0.24944712221622467, 'eval_runtime': 214.7262, 'eval_samples_per_second': 1.043, 'eval_steps_per_second': 1.043, 'step': 98}, {'epoch': 1.0204081632653061, 'grad_norm': 0.00686634099110961, 'learning_rate': 0.00016700680272108845, 'loss': 0.3578, 'step': 100}, {'epoch': 1.1224489795918366, 'grad_norm': 0.16006037592887878, 'learning_rate': 0.00016360544217687074, 'loss': 0.2331, 'step': 110}, {'epoch': 1.2244897959183674, 'grad_norm': 1.5165075063705444, 'learning_rate': 0.00016020408163265306, 'loss': 0.2638, 'step': 120}, {'epoch': 1.3265306122448979, 'grad_norm': 1.62991201877594, 'learning_rate': 0.00015680272108843538, 'loss': 0.4276, 'step': 130}, {'epoch': 1.4285714285714286, 'grad_norm': 1.1211175918579102, 'learning_rate': 0.0001534013605442177, 'loss': 0.2084, 'step': 140}, {'epoch': 1.5306122448979593, 'grad_norm': 0.8810230493545532, 'learning_rate': 0.00015000000000000001, 'loss': 0.3106, 'step': 150}, {'epoch': 1.6326530612244898, 'grad_norm': 0.3241180181503296, 'learning_rate': 0.0001465986394557823, 'loss': 0.1775, 'step': 160}, {'epoch': 1.7346938775510203, 'grad_norm': 0.4346107244491577, 'learning_rate': 0.00014319727891156463, 'loss': 0.4012, 'step': 170}, {'epoch': 1.836734693877551, 'grad_norm': 0.986940860748291, 'learning_rate': 0.00013979591836734694, 'loss': 0.3272, 'step': 180}, {'epoch': 1.9387755102040818, 'grad_norm': 1.0687965154647827, 'learning_rate': 0.00013639455782312926, 'loss': 0.3455, 'step': 190}, {'epoch': 2.0, 'eval_loss': 0.24124164879322052, 'eval_runtime': 214.7338, 'eval_samples_per_second': 1.043, 'eval_steps_per_second': 1.043, 'step': 196}, {'epoch': 2.0408163265306123, 'grad_norm': 0.23889683187007904, 'learning_rate': 0.00013299319727891158, 'loss': 0.1417, 'step': 200}, {'epoch': 2.142857142857143, 'grad_norm': 0.9660771489143372, 'learning_rate': 0.00012959183673469387, 'loss': 0.2051, 'step': 210}, {'epoch': 2.2448979591836733, 'grad_norm': 0.7280988097190857, 'learning_rate': 0.0001261904761904762, 'loss': 0.2864, 'step': 220}, {'epoch': 2.3469387755102042, 'grad_norm': 0.5104873180389404, 'learning_rate': 0.0001227891156462585, 'loss': 0.3215, 'step': 230}, {'epoch': 2.4489795918367347, 'grad_norm': 0.39726802706718445, 'learning_rate': 0.00011938775510204083, 'loss': 0.2036, 'step': 240}, {'epoch': 2.5510204081632653, 'grad_norm': 1.342177152633667, 'learning_rate': 0.00011598639455782314, 'loss': 0.2219, 'step': 250}, {'epoch': 2.6530612244897958, 'grad_norm': 0.2646348476409912, 'learning_rate': 0.00011258503401360546, 'loss': 0.1827, 'step': 260}, {'epoch': 2.7551020408163263, 'grad_norm': 0.09917673468589783, 'learning_rate': 0.00010918367346938776, 'loss': 0.198, 'step': 270}, {'epoch': 2.857142857142857, 'grad_norm': 0.31997281312942505, 'learning_rate': 0.00010578231292517007, 'loss': 0.3707, 'step': 280}, {'epoch': 2.9591836734693877, 'grad_norm': 0.42144495248794556, 'learning_rate': 0.00010238095238095237, 'loss': 0.1981, 'step': 290}, {'epoch': 3.0, 'eval_loss': 0.2528705596923828, 'eval_runtime': 214.6898, 'eval_samples_per_second': 1.043, 'eval_steps_per_second': 1.043, 'step': 294}, {'epoch': 3.061224489795918, 'grad_norm': 1.0238592624664307, 'learning_rate': 9.897959183673469e-05, 'loss': 0.1833, 'step': 300}, {'epoch': 3.163265306122449, 'grad_norm': 0.6676089763641357, 'learning_rate': 9.557823129251701e-05, 'loss': 0.1074, 'step': 310}, {'epoch': 3.2653061224489797, 'grad_norm': 0.4872434735298157, 'learning_rate': 9.217687074829933e-05, 'loss': 0.2235, 'step': 320}, {'epoch': 3.36734693877551, 'grad_norm': 1.8725162744522095, 'learning_rate': 8.877551020408164e-05, 'loss': 0.1733, 'step': 330}, {'epoch': 3.4693877551020407, 'grad_norm': 1.7161154747009277, 'learning_rate': 8.537414965986394e-05, 'loss': 0.2314, 'step': 340}, {'epoch': 3.571428571428571, 'grad_norm': 0.49272969365119934, 'learning_rate': 8.197278911564626e-05, 'loss': 0.2129, 'step': 350}, {'epoch': 3.673469387755102, 'grad_norm': 1.1436607837677002, 'learning_rate': 7.857142857142858e-05, 'loss': 0.1758, 'step': 360}, {'epoch': 3.7755102040816326, 'grad_norm': 1.1257497072219849, 'learning_rate': 7.517006802721089e-05, 'loss': 0.1849, 'step': 370}, {'epoch': 3.877551020408163, 'grad_norm': 0.6632790565490723, 'learning_rate': 7.17687074829932e-05, 'loss': 0.1849, 'step': 380}, {'epoch': 3.979591836734694, 'grad_norm': 1.0515093803405762, 'learning_rate': 6.836734693877551e-05, 'loss': 0.2082, 'step': 390}, {'epoch': 4.0, 'eval_loss': 0.28270527720451355, 'eval_runtime': 214.7404, 'eval_samples_per_second': 1.043, 'eval_steps_per_second': 1.043, 'step': 392}, {'epoch': 4.081632653061225, 'grad_norm': 0.0004894266603514552, 'learning_rate': 6.496598639455783e-05, 'loss': 0.1463, 'step': 400}, {'epoch': 4.183673469387755, 'grad_norm': 1.605027198791504, 'learning_rate': 6.156462585034013e-05, 'loss': 0.0699, 'step': 410}, {'epoch': 4.285714285714286, 'grad_norm': 0.4674456715583801, 'learning_rate': 5.816326530612245e-05, 'loss': 0.1242, 'step': 420}, {'epoch': 4.387755102040816, 'grad_norm': 2.025743246078491, 'learning_rate': 5.4761904761904766e-05, 'loss': 0.1548, 'step': 430}, {'epoch': 4.489795918367347, 'grad_norm': 1.7600548267364502, 'learning_rate': 5.136054421768708e-05, 'loss': 0.181, 'step': 440}, {'epoch': 4.591836734693878, 'grad_norm': 0.305524617433548, 'learning_rate': 4.795918367346939e-05, 'loss': 0.0974, 'step': 450}, {'epoch': 4.6938775510204085, 'grad_norm': 2.290829658508301, 'learning_rate': 4.4557823129251704e-05, 'loss': 0.1913, 'step': 460}, {'epoch': 4.795918367346939, 'grad_norm': 1.0626986026763916, 'learning_rate': 4.1156462585034016e-05, 'loss': 0.1898, 'step': 470}, {'epoch': 4.8979591836734695, 'grad_norm': 0.47128549218177795, 'learning_rate': 3.775510204081633e-05, 'loss': 0.151, 'step': 480}, {'epoch': 5.0, 'grad_norm': 2.826014995574951, 'learning_rate': 3.435374149659864e-05, 'loss': 0.194, 'step': 490}, {'epoch': 5.0, 'eval_loss': 0.2994394302368164, 'eval_runtime': 214.7622, 'eval_samples_per_second': 1.043, 'eval_steps_per_second': 1.043, 'step': 490}, {'epoch': 5.1020408163265305, 'grad_norm': 0.5346373319625854, 'learning_rate': 3.095238095238095e-05, 'loss': 0.0898, 'step': 500}, {'epoch': 5.204081632653061, 'grad_norm': 1.846283197402954, 'learning_rate': 2.7551020408163265e-05, 'loss': 0.1016, 'step': 510}, {'epoch': 5.3061224489795915, 'grad_norm': 1.5938162803649902, 'learning_rate': 2.4149659863945578e-05, 'loss': 0.1106, 'step': 520}, {'epoch': 5.408163265306122, 'grad_norm': 0.8825483322143555, 'learning_rate': 2.0748299319727893e-05, 'loss': 0.1078, 'step': 530}, {'epoch': 5.510204081632653, 'grad_norm': 0.6776874661445618, 'learning_rate': 1.7346938775510206e-05, 'loss': 0.1062, 'step': 540}, {'epoch': 5.612244897959184, 'grad_norm': 2.3200759887695312, 'learning_rate': 1.3945578231292516e-05, 'loss': 0.1285, 'step': 550}, {'epoch': 5.714285714285714, 'grad_norm': 1.314473032951355, 'learning_rate': 1.054421768707483e-05, 'loss': 0.1232, 'step': 560}, {'epoch': 5.816326530612245, 'grad_norm': 2.6448588371276855, 'learning_rate': 7.142857142857143e-06, 'loss': 0.1106, 'step': 570}, {'epoch': 5.918367346938775, 'grad_norm': 1.1177891492843628, 'learning_rate': 3.741496598639456e-06, 'loss': 0.1015, 'step': 580}, {'epoch': 6.0, 'eval_loss': 0.3326365649700165, 'eval_runtime': 214.6812, 'eval_samples_per_second': 1.043, 'eval_steps_per_second': 1.043, 'step': 588}, {'train_runtime': 0.1266, 'train_samples_per_second': 37147.855, 'train_steps_per_second': 4643.482, 'total_flos': 6.03494372081664e+17, 'train_loss': 0.0, 'epoch': 6.0, 'step': 588}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers.integrations import MLflowCallback\n",
    "import os\n",
    "import glob\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1, # 1 sample per device due to GPU memory constraints\n",
    "    per_device_eval_batch_size=1, # 1 sample per device due to GPU memory constraints\n",
    "    gradient_accumulation_steps=8, # to accumulate gradients update over multiple steps to simulate larger batch sizes\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=10,#10\n",
    "    log_level=\"info\", # set log level to info to see training progress\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    # save_steps=500,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    load_best_model_at_end=True,\n",
    "    output_dir=checkpoint_dir,\n",
    "    label_names=[\"labels\"],\n",
    "    disable_tqdm=False, # enable tqdm progress bars\n",
    "    gradient_checkpointing=True, # to train large models with limited GPU memory\n",
    "    save_total_limit=4, # keep only the last 4 checkpoints to save space\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    args=training_args\n",
    ")\n",
    "\n",
    "trainer.add_callback(MLflowCallback)\n",
    "\n",
    "resume_from_checkpoint = None\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    # Find all checkpoint folders in the checkpoint_dir by extracting the checkpoint index\n",
    "    checkpoint_paths = glob.glob(os.path.join(checkpoint_dir, \"checkpoint-*\"))\n",
    "    if checkpoint_paths:\n",
    "        # Extract checkpoint indices and sort by the integer value\n",
    "        checkpoint_indices = [\n",
    "            (int(os.path.basename(path).split(\"-\")[-1]), path)\n",
    "            for path in checkpoint_paths\n",
    "            if os.path.basename(path).split(\"-\")[-1].isdigit()\n",
    "        ]\n",
    "        if checkpoint_indices:\n",
    "            # Get the path with the highest checkpoint index\n",
    "            latest_checkpoint = max(checkpoint_indices, key=lambda x: x[0])[1]\n",
    "            resume_from_checkpoint = latest_checkpoint\n",
    "            print(f\"Resuming training from latest checkpoint: {resume_from_checkpoint}\")\n",
    "        else:\n",
    "            print(\"No valid checkpoint found. Starting training from scratch.\")\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "else:\n",
    "    print(\"No checkpoint directory found. Starting training from scratch.\") \n",
    "\n",
    "\n",
    "trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
    "\n",
    "print(trainer.state.log_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefcfcf",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ffc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-Instruct-v0.3\\snapshots\\0d4b76e1efeb5eb6f6b5e757c79870472e04bd3a\\config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": null,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "chat template saved in ../output/Approach_2_Property_Style/adapters/epoch-6\\chat_template.jinja\n",
      "tokenizer config file saved in ../output/Approach_2_Property_Style/adapters/epoch-6\\tokenizer_config.json\n",
      "Special tokens file saved in ../output/Approach_2_Property_Style/adapters/epoch-6\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ../output/Approach_2_Property_Style/adapters/epoch-6\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "trainer.model.save_pretrained(model_output_dir)\n",
    "tokenizer.save_pretrained(model_output_dir)\n",
    "\n",
    "mlflow.log_artifact(model_output_dir, artifact_path=\"adapters\")  \n",
    "\n",
    "mlflow.end_run()  # End the MLflow run\n",
    "print(f\"Model and tokenizer saved to {model_output_dir}\")\n",
    "\n",
    "shutil.rmtree(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mlflow ui --backend-store-uri file:./mlruns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic-data-generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
