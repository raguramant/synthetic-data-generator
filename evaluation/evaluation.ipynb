{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b5f461",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8b8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "#Model configs\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "checkpoint_dir = \"../output/checkpoints\"\n",
    "model_output_dir = \"../output/final_adapter\"\n",
    "training_data = \"../data/combinations.jsonl\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78af39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 28 15:13:09 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.40                 Driver Version: 576.40         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5070 Ti   WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   43C    P8             19W /  300W |    7204MiB /  16303MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             812      C   ...s\\Admin\\miniconda3\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           11792      C   ...s\\Admin\\miniconda3\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdcf5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "\n",
    "# load the dataset and split it into train, validation and test sets\n",
    "dataset = load_dataset(\"json\", data_files=training_data, split='train')\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "train_temp_split = shuffled_dataset.train_test_split(test_size=0.3) #30% for validation and test\n",
    "temp_dataset = train_temp_split['test']\n",
    "validation_test_split = temp_dataset.train_test_split(test_size=1/3)# 10% for validation and 20% for test\n",
    "split_datasets = DatasetDict({\n",
    "    'train': train_temp_split['train'],\n",
    "    'validation': validation_test_split['train'],\n",
    "    'test': validation_test_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512bd59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac8f6c08b26482ea8a3faa4345ca062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                                    quantization_config=quantization_config , \n",
    "                                                    device_map=\"auto\")\n",
    "    \n",
    "model = PeftModel.from_pretrained(base_model, model_output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228faf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from jsonschema import validate, ValidationError\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "\n",
    "# function to extact JSON from a string\n",
    "def find_and_parse_json(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Finds the first valid JSON object in a string and parses it.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the first opening curly brace\n",
    "        first_brace_index = text.find('{')\n",
    "        if first_brace_index == -1:\n",
    "            return None # No JSON object found\n",
    "\n",
    "        # Start searching from the first brace\n",
    "        brace_level = 1\n",
    "        for i, char in enumerate(text[first_brace_index + 1:]):\n",
    "            if char == '{':\n",
    "                brace_level += 1\n",
    "            elif char == '}':\n",
    "                brace_level -= 1\n",
    "            \n",
    "            if brace_level == 0:\n",
    "                # We found the matching closing brace\n",
    "                last_brace_index = first_brace_index + i + 1\n",
    "                json_string = text[first_brace_index : last_brace_index + 1]\n",
    "                \n",
    "                # Now, use the built-in json library to parse it\n",
    "                return json.loads(json_string)\n",
    "        \n",
    "        return None # No complete JSON object found\n",
    "    except (json.JSONDecodeError, IndexError):\n",
    "        # Handle cases where the substring is not valid JSON or string is malformed\n",
    "        return None\n",
    "\n",
    "\n",
    "# Validate a JSON string against a schema\n",
    "def is_valid_json_schema(json_generated, schema):\n",
    "    try:\n",
    "        validate(instance=json_generated, schema=schema)\n",
    "        return True\n",
    "    except (json.JSONDecodeError, ValidationError):\n",
    "        return False\n",
    "    \n",
    "# Compare two JSON strings at field level and match field values\n",
    "def compare_json_field_values(json_ref, json_gen):\n",
    "    obj1=json_ref\n",
    "    obj2=json_gen\n",
    "    matching_fields = []\n",
    "    matching_values = 0\n",
    "    total_fields = max(len(obj1), len(obj2))\n",
    "    for key in obj1:\n",
    "        if key in obj2:\n",
    "            matching_fields.append(key)\n",
    "            if obj1[key] == obj2[key]:\n",
    "                matching_values += 1\n",
    "    score = matching_values\n",
    "    percentage = score / total_fields if total_fields > 0 else 0\n",
    "    result = {\n",
    "        \"matching_fields\": matching_fields,\n",
    "        \"matching_values\": score,\n",
    "        \"total_fields\": total_fields,\n",
    "        \"percentage\": percentage\n",
    "    }\n",
    "    return result['percentage']\n",
    "\n",
    "def get_result(valid_json, valid_json_schema, comparison_results):\n",
    "    return json.dumps({\n",
    "        \"valid_json\": np.mean(valid_json) * 100,\n",
    "        \"valid_json_schema\": np.mean(valid_json_schema) * 100,\n",
    "        \"comparison_results\": np.mean(comparison_results) * 100\n",
    "    })\n",
    "\n",
    "\n",
    "def test_model(model, tokenizer, test_dataset):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    valid_json = []\n",
    "    valid_json_schema = []\n",
    "    comparison_results = []\n",
    "\n",
    "    stop_words = [\"[INST]\"]\n",
    "    stop_word_ids = [tokenizer(stop_word, add_special_tokens=False).input_ids[0] for stop_word in stop_words]\n",
    "    stop_word_ids.append(tokenizer.eos_token_id)  # Add EOS token ID to the stop words\n",
    "    print(f\"Tokens to stop on: {stop_words}\")\n",
    "    print(f\"Corresponding Token IDs: {stop_word_ids}\")\n",
    "        \n",
    "    for i, row in enumerate(test_dataset):\n",
    "\n",
    "        print(f\"Processing row {i+1}/{len(test_dataset)}\")\n",
    "\n",
    "        prompt = f\"<s>[INST] {row['messages'][0]['content']} [/INST]\"\n",
    "        # print(f\"Prompt: \\n {prompt} \\n ---------------------------------\")\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,                \n",
    "                top_p=0.9,\n",
    "                eos_token_id=stop_word_ids\n",
    "            )\n",
    "\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "        # print(f\"Generated text: \\n {generated_text} \\n ---------------------------------\")\n",
    "        \n",
    "        if(\"[/INST]\" in generated_text):\n",
    "            generated_json = find_and_parse_json(generated_text.split(\"[/INST]\")[-1].strip())\n",
    "            gold_json = find_and_parse_json(row['messages'][1]['content'])\n",
    "            schema = find_and_parse_json(generated_text.split(\"[/INST]\")[-2].strip())\n",
    "            # print(f\"Generated JSON: {generated_json} \\n Goled JSON: {gold_json} \\n Schema: {schema}\")\n",
    "        \n",
    "        if generated_json is not None:\n",
    "            valid_json.append(True)\n",
    "        else:\n",
    "            valid_json.append(False)\n",
    "\n",
    "        \n",
    "        if schema is not None:\n",
    "            if generated_json is not None and is_valid_json_schema(generated_json, schema):\n",
    "                valid_json_schema.append(True)\n",
    "            else:\n",
    "                valid_json_schema.append(False)\n",
    "        \n",
    "        if gold_json is not None:\n",
    "            if generated_json is not None:\n",
    "                comparison_score = compare_json_field_values(gold_json, generated_json)\n",
    "            else:\n",
    "                comparison_score = 0.0\n",
    "            comparison_results.append(comparison_score)\n",
    "\n",
    "        print(get_result(valid_json, valid_json_schema, comparison_results))\n",
    "\n",
    "    \n",
    "    return get_result(valid_json, valid_json_schema, comparison_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2004234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens to stop on: ['[INST]']\n",
      "Corresponding Token IDs: [3, 2]\n",
      "Processing row 1/1\n",
      "{'valid_json': np.float64(100.0), 'valid_json_schema': np.float64(100.0), 'comparison_results': np.float64(10.0)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'valid_json': np.float64(100.0),\n",
       " 'valid_json_schema': np.float64(100.0),\n",
       " 'comparison_results': np.float64(10.0)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, tokenizer, split_datasets[\"test\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
