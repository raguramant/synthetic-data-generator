{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b5f461",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e8b8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from transformers import BitsAndBytesConfig\n",
    "#Model configs\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "checkpoint_dir = \"../output/checkpoints\"\n",
    "model_output_dir = \"../output/final_adapter\"\n",
    "training_data = \"../data/combinations.jsonl\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78af39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 30 23:44:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.40                 Driver Version: 576.40         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5070 Ti   WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   38C    P8              8W /  300W |    8767MiB /  16303MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            8056      C   ...s\\Admin\\miniconda3\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdcf5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "\n",
    "# load the dataset and split it into train, validation and test sets\n",
    "dataset = load_dataset(\"json\", data_files=training_data, split='train')\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "train_temp_split = shuffled_dataset.train_test_split(test_size=0.3) #30% for validation and test\n",
    "temp_dataset = train_temp_split['test']\n",
    "validation_test_split = temp_dataset.train_test_split(test_size=1/3)# 10% for validation and 20% for test\n",
    "split_datasets = DatasetDict({\n",
    "    'train': train_temp_split['train'],\n",
    "    'validation': validation_test_split['train'],\n",
    "    'test': validation_test_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "512bd59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8c32523aca43abaddf46bbd5460c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                                    quantization_config=quantization_config , \n",
    "                                                    device_map=\"auto\")\n",
    "    \n",
    "model = PeftModel.from_pretrained(base_model, model_output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228faf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from jsonschema import validate, ValidationError\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "\n",
    "# function to extact JSON from a string\n",
    "def find_and_parse_json(text: str) -> dict:\n",
    "\n",
    "    try:\n",
    "        # Find the first opening curly brace\n",
    "        first_brace_index = text.find('{')\n",
    "        if first_brace_index == -1:\n",
    "            return None # No JSON object found\n",
    "\n",
    "        # Start searching from the first brace\n",
    "        brace_level = 1\n",
    "        for i, char in enumerate(text[first_brace_index + 1:]):\n",
    "            if char == '{':\n",
    "                brace_level += 1\n",
    "            elif char == '}':\n",
    "                brace_level -= 1\n",
    "            \n",
    "            if brace_level == 0:\n",
    "                # We found the matching closing brace\n",
    "                last_brace_index = first_brace_index + i + 1\n",
    "                json_string = text[first_brace_index : last_brace_index + 1]\n",
    "                \n",
    "                # Now, use the built-in json library to parse it\n",
    "                return json.loads(json_string)\n",
    "        \n",
    "        return None # No complete JSON object found\n",
    "    except (json.JSONDecodeError, IndexError):\n",
    "        # Handle cases where the substring is not valid JSON or string is malformed\n",
    "        return None\n",
    "\n",
    "\n",
    "# Validate a JSON string against a schema\n",
    "def is_valid_json_schema(json_generated, schema):\n",
    "    try:\n",
    "        validate(instance=json_generated, schema=schema)\n",
    "        return True\n",
    "    except (json.JSONDecodeError, ValidationError):\n",
    "        return False\n",
    "    \n",
    "# Compare two JSON strings at field level and match field values\n",
    "def compare_json_field_values(json_ref, json_gen):\n",
    "\n",
    "    \n",
    "    if not isinstance(json_ref, dict) or not isinstance(json_gen, dict):\n",
    "        return 0.0\n",
    "    \n",
    "    score = 10\n",
    "    # json_gen has all fields of json_ref, if not reduce the score proportional to no of fields missing\n",
    "    if set(json_gen.keys()).issubset(set(json_ref.keys())):\n",
    "        for key in json_ref.keys():\n",
    "            if json_gen.get(key) is None:\n",
    "                reduce_score = 3 / len(json_ref.keys())\n",
    "                logger.debug(f\"Key {key} is missing in json_gen, reducing score by {reduce_score}\")\n",
    "                score -= reduce_score\n",
    "    else:\n",
    "        reduce_score = (len(json_ref.keys()) - len(json_gen.keys())) * (3 / len(json_ref.keys()))\n",
    "        logger.debug(f\"Keys in json_ref not present in json_gen, reducing score by {reduce_score}\")\n",
    "        score -= reduce_score\n",
    "\n",
    "    # Compare values of each field if they dont match reduce the score proportional to no of fields not matching in a scale of  0 to 5\n",
    "    count_mismatch = 0\n",
    "    for key in json_ref.keys():\n",
    "        if key in json_gen:\n",
    "            if json_ref[key] != json_gen[key]:\n",
    "                count_mismatch += 1\n",
    "        else:\n",
    "            count_mismatch += 1\n",
    "    count_mismatch/= len(json_ref.keys())\n",
    "    logger.debug(f\"Count of mismatched fields: {count_mismatch*2}\")    \n",
    "    score -= count_mismatch * 2\n",
    "\n",
    "    # domainn specific checks\n",
    "    if 'nm1_segment' in json_ref.keys():\n",
    "        # Check if NM1 segment is present in both JSONs\n",
    "        logger.debug(f\"{json_ref['nm1_segment']}  {json_gen.get('nm1_segment')}\")\n",
    "        if 'nm1_segment' in json_gen.keys():\n",
    "            #NM1*PR*2*Palmer*Darlene*M*Mr.*DVM*PI*SqLFzolMNdaVXE~\n",
    "            pattern = r'^NM1(?:\\*[^*]*){9}~$'\n",
    "            value = json_gen[key]\n",
    "            if not bool(re.match(pattern, value)):\n",
    "                score -= 2.5\n",
    "                logger.debug(f\"NM1 segment {value} does not match the expected pattern, reducing score by 2.5\")\n",
    "            # check if all values in the json_gen are present in the value except for the nm1_segment\n",
    "            for key in json_gen.keys():\n",
    "                if key != 'nm1_segment' and json_gen[key] not in value:\n",
    "                    score -= 2.5\n",
    "                    logger.debug(f\"Value {json_gen[key]} not found in NM1 segment {value}, reducing score by 2.5\")\n",
    "                    break\n",
    "        else:\n",
    "            score -= 5\n",
    "            logger.debug(f\"NM1 segment not found in json_gen, reducing score by 5\")\n",
    "\n",
    "\n",
    "    # If the score is less than 0, set it to 0\n",
    "    if score < 0:\n",
    "        score = 0.0\n",
    "\n",
    "    logger.debug(f\"Final score: {score}\")\n",
    "\n",
    "    return score\n",
    "\n",
    "def get_result(valid_json, valid_json_schema, comparison_results):\n",
    "    return json.dumps({\n",
    "        \"valid_json\": np.mean(valid_json) * 100,\n",
    "        \"valid_json_schema\": np.mean(valid_json_schema) * 100,\n",
    "        \"domain_field_match\": np.mean(comparison_results) * 10\n",
    "    })\n",
    "\n",
    "\n",
    "def test_model(model, tokenizer, test_dataset):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    valid_json = []\n",
    "    valid_json_schema = []\n",
    "    comparison_results = []\n",
    "\n",
    "    stop_words = [\"[INST]\"]\n",
    "    stop_word_ids = [tokenizer(stop_word, add_special_tokens=False).input_ids[0] for stop_word in stop_words]\n",
    "    stop_word_ids.append(tokenizer.eos_token_id)  # Add EOS token ID to the stop words\n",
    "    print(f\"Tokens to stop on: {stop_words}\")\n",
    "    print(f\"Corresponding Token IDs: {stop_word_ids}\")\n",
    "        \n",
    "    for i, row in enumerate(test_dataset):\n",
    "\n",
    "        print(f\"Processing row {i+1}/{len(test_dataset)}\")\n",
    "\n",
    "        prompt = f\"<s>[INST] {row['messages'][0]['content']} [/INST]\"\n",
    "        # print(f\"Prompt: \\n {prompt} \\n ---------------------------------\")\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,                \n",
    "                top_p=0.9,\n",
    "                eos_token_id=stop_word_ids\n",
    "            )\n",
    "\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "        # print(f\"Generated text: \\n {generated_text} \\n ---------------------------------\")\n",
    "        \n",
    "        if(\"[/INST]\" in generated_text):\n",
    "            generated_json = find_and_parse_json(generated_text.split(\"[/INST]\")[-1].strip())\n",
    "            gold_json = find_and_parse_json(row['messages'][1]['content'])\n",
    "            schema = find_and_parse_json(generated_text.split(\"[/INST]\")[-2].strip())\n",
    "            # print(f\"Generated JSON: {generated_json} \\n Goled JSON: {gold_json} \\n Schema: {schema}\")\n",
    "        \n",
    "        # is Json valid?\n",
    "        if generated_json is not None:\n",
    "            valid_json.append(True)\n",
    "        else:\n",
    "            valid_json.append(False)\n",
    "\n",
    "        # is JSON valid against schema?\n",
    "        if schema is not None:\n",
    "            if generated_json is not None and is_valid_json_schema(generated_json, schema):\n",
    "                valid_json_schema.append(True)\n",
    "            else:\n",
    "                valid_json_schema.append(False)\n",
    "        \n",
    "        # compare JSON field values\n",
    "        if gold_json is not None:\n",
    "            if generated_json is not None:\n",
    "                comparison_score = compare_json_field_values(gold_json, generated_json)\n",
    "            else:\n",
    "                comparison_score = 0.0\n",
    "            comparison_results.append(comparison_score)\n",
    "\n",
    "        logger.info(get_result(valid_json, valid_json_schema, comparison_results))\n",
    "\n",
    "    \n",
    "    return get_result(valid_json, valid_json_schema, comparison_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2004234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens to stop on: ['[INST]']\n",
      "Corresponding Token IDs: [3, 2]\n",
      "Processing row 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Keys in json_ref not present in json_gen, reducing score by -0.375\n",
      "DEBUG - Count of mismatched fields: 2.0\n",
      "DEBUG - NM1*IL*1*Willis*Cheryl***Jr.*XX*DFtlAnEqvtROQMDLhkjELWnql~  NM1*03*2*Garcia*Jennifer*D*Mr.**PI*JJcQJHXhjtPWwUHhJJUjWbXnUJMbjDm~\n",
      "DEBUG - NM1 segment NM1*03*2*Garcia*Jennifer*D*Mr.**PI*JJcQJHXhjtPWwUHhJJUjWbXnUJMbjDm~ does not match the expected pattern, reducing score by 2.5\n",
      "DEBUG - Final score: 5.875\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 58.75}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Count of mismatched fields: 1.4\n",
      "DEBUG - NM1*IL*1*Moss*Sean*B*Miss*PhD*PI*OCUrWoTpVGZHDEkEZgfTidcqAksi~  NM1*IL*1*Harris*Jeremy*R*Mrs.*Jr.*PI*KIUQKxTWcZDgBpqmEGdqwVyHrUvLKbW~\n",
      "DEBUG - Final score: 8.6\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 72.375}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Count of mismatched fields: 0.0\n",
      "DEBUG - NM1*PR*2*Davis*Edward*V**DDS*PI*PCJkdlcPdwLVynEsUchRDDIyre~  NM1*PR*2*Davis*Edward*V**DDS*PI*PCJkdlcPdwLVynEsUchRDDIyre~\n",
      "DEBUG - NM1 segment NM1*PR*2*Davis*Edward*V**DDS*PI*PCJkdlcPdwLVynEsUchRDDIyre~ does not match the expected pattern, reducing score by 2.5\n",
      "DEBUG - Final score: 7.5\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 73.25}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Count of mismatched fields: 0.0\n",
      "DEBUG - NM1*IL*1*Stokes*Alejandro*U**DDS**~  NM1*IL*1*Stokes*Alejandro*U**DDS**~\n",
      "DEBUG - NM1 segment NM1*IL*1*Stokes*Alejandro*U**DDS**~ does not match the expected pattern, reducing score by 2.5\n",
      "DEBUG - Final score: 7.5\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 73.6875}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Count of mismatched fields: 1.4\n",
      "DEBUG - NM1*IL*2*Valencia*Brian*Y*Mx.*MD*MI*BVUAfvezYTDvNARKXtuGxTGTsVmeWIwSqftz~  NM1*IL*2*Rivera*Matthew*K*Mx.*DDS*PI*jNHrIWwXWYDGYzHwFqBtDmQv~\n",
      "DEBUG - Final score: 8.6\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 76.15}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Count of mismatched fields: 1.3333333333333333\n",
      "DEBUG - NM1*03*1*Lambert****MD*XX*~  NM1*03*1*Caldwell**DDS*SV*~\n",
      "DEBUG - NM1 segment NM1*03*1*Caldwell**DDS*SV*~ does not match the expected pattern, reducing score by 2.5\n",
      "DEBUG - Final score: 6.166666666666666\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 73.73611111111111}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Count of mismatched fields: 0.0\n",
      "DEBUG - NM1*1P*1*Barrett**J*Mx.*MD**BTopyVU~  NM1*1P*1*Barrett**J*Mx.*MD**BTopyVU~\n",
      "DEBUG - NM1 segment NM1*1P*1*Barrett**J*Mx.*MD**BTopyVU~ does not match the expected pattern, reducing score by 2.5\n",
      "DEBUG - Final score: 7.5\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 73.91666666666667}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Keys in json_ref not present in json_gen, reducing score by 0.0\n",
      "DEBUG - Count of mismatched fields: 1.7777777777777777\n",
      "DEBUG - NM1*PR*1*Evans*Jeffery*F**II*SV*DUvFMrOCGkdtxsAYMJhcWGSdaiunCBaZdaxEvcGuhJLMUrSm~  NM1*03*1*Murphy*Joseph*L*Ms.*DDS**GKOjcFwCeMzQRKgLQTfzUFQrPXKtQxYKwjUWwZHUHvzCgWxK~\n",
      "DEBUG - NM1 segment NM1*03*1*Murphy*Joseph*L*Ms.*DDS**GKOjcFwCeMzQRKgLQTfzUFQrPXKtQxYKwjUWwZHUHvzCgWxK~ does not match the expected pattern, reducing score by 2.5\n",
      "DEBUG - Final score: 5.722222222222221\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 71.82986111111111}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Count of mismatched fields: 0.0\n",
      "DEBUG - NM1*PR*2*Tucker*Michael*M*Mx.*MD*PI*~  NM1*PR*2*Tucker*Michael*M*Mx.*MD*PI*~\n",
      "DEBUG - NM1 segment NM1*PR*2*Tucker*Michael*M*Mx.*MD*PI*~ does not match the expected pattern, reducing score by 2.5\n",
      "DEBUG - Final score: 7.5\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 72.1820987654321}\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Keys in json_ref not present in json_gen, reducing score by -0.3333333333333333\n",
      "DEBUG - Count of mismatched fields: 1.7777777777777777\n",
      "DEBUG - NM1*PR*2*Howell*Andrea*A*Mx.**PI*rhoxepNgGoHi~  NM1*PR*1*Hill*Jennifer*F*Mr.*Jr.*SV*NrFmYOYMnLUHlzcFUmJbIgfqoJZKtQpJwzRjrJJtXgmUJpMfO~\n",
      "DEBUG - Final score: 8.555555555555557\n",
      "INFO - {\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 73.51944444444445}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"valid_json\": 100.0, \"valid_json_schema\": 100.0, \"domain_field_match\": 73.51944444444445}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG) \n",
    "test_model(model, tokenizer, split_datasets[\"test\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
